file: ../MeqTrees/PSS5.27oct2004


===============================================================================
Here is some of the stuff we came up with in the ADASS week.
It is (very) important, but in a somewhat later phase.
(I am only including it here for later reference)
===============================================================================


Participants:
  - RXA: Rob Assendorp
  - MAB: Michiel Brentjens
  - GVD: Ger van Diepen
  - RJN: Ronald Nijboer 
  - JEN: Jan Noordam
  - TAO: Tom Oosterloo
  - OMS: Oleg Smirnov
  - AGW: Tony Willis

  - HAH: Hanno Holties
  - KVS: Kjeld van der Schaaf
  - CMV: Marco de Vos





           Report from ADASS
	   =================

OMS and JEN have conducted a 'focus group' meeting about 'taming the
Measurement Equation with MeqTrees', and presented a poster, at ADASS
2004 in Pasadena. Participation was small, but of high quality,
including Tim Cornwell, Sanjay Bhatnagar, Brian Glendenning, Athol
Kemball and Harro Verkouter. We detected some genuine interest in our
approach, and a willingness to exploit the complementarity of MeqTree
calibration and AIPS++ imaging.

A valuable result for us was a possible solution of the open problem
of the best way to predict Cat II sources where the instrumental
errors vary over the Cat II patch (see below). Sanjay might visit us
on his way to GMRT to discuss this further.

In the plane, we made considerable progress in the area of MeqParm
behaviour (see below). However, open questions remain.

I discussed ALMA processing with Brian Glendenning. He controls a
budget of 37 M$(!), and has 50 people spread out over the globe.
He confirmed that AIPS++ is the only contender for off-line data
processing, but he is not directly involved in the details. 

Some VO-related matters:

   1) At the request of Roy Williams, JEN participated in a VO
   discussion about Universal Content Descriptors (UCD). Getting this
   right is important, because it determines the ability to
   cross-reference different archives. The group around Ed Shay has
   developed an astronomical 'ontology' (hierarchical system of terms)
   and are pondering how to get the community to adopt it. The latter
   will only happen if there is a set of tools to automatically
   convert an existing archive. They were interested in our suggestion
   of defining UCD's in terms of an embedded mathematical expression
   (string) of existing UCD's. Next year we will point out the use of
   MeqTrees in the GSM/LSM.

   2) Jonathan McDowell (no relation), the chairman of the VO Data
   Model group was greatly interested in the Measurement Equation, and
   our the use of our kernel to solve for its parameters. He sees it
   as apossibility to solve for the shape of the PSF in X-ray imaging,
   the treatment of which is rather sub-optimal as yet.



             MeqParm behaviour
	     =================

As mentioned above, JEN and OMS made some progress in defining the
behaviour of solvable MeqParms (i.e. MeqParms that have been set to
solvable). The proposed scheme is as follows:

   -) For each 10-100 sec snippet, we solve for the freq-coeffs only:
   c00, c0f, c0f^2, c0f^3 etc. Of course we predict for the smallest
   number of freq-bins.

   -) Each MeqParm accumulates a solution matrix for the coefficients
   of the larger polc, i.e. the ones that has the full degree in time
   also. Each new snippet solution contributes new equations for this
   local matrix.

   -) The local matrix is inverted to predict the values for the next
   snippet. In this way, the prediction is made with coefficients that
   are the result of a many-snippet solution (i.e. low S/N).

   -) Bad solutions may be ignored by rejecting dp values that are
   much larger than the expected variations....

   -) This approach minimises the size of the selfcal solution matrix,
   and also the number of derivatives that have to be calculated.

   -) It also offers a flexible way to deal with discontinuities in
   time, like phase-jumps (freq-julmps are much less likely).

Summarizing, we think that this is a simple and workable scheme for
the behaviour of MeqParms while they are being solved. It has clear
and policy-free rules, and the S/N is probably close to optimal.

We still need some more progress on the following MeqParm issues:

   -) A MeqParm is supposed to ALWAYS values for a requested domain,
   using a weighted combination of its available polcs, or its default
   value. We have discussed some possibilities in the past. One of the
   bottlenecks is the treatment of discontinutites (e.g. phase-jumps)
   and contradictions.

   -) Visualisation of (groups of) MeqParms.

   -) After parallel solutions for a domain mosaic of frequency bands
   and time chunks (of an hour, say), we need to detect and smooth any
   edge discontinuties between the solutions.

   -) Setting initial MeqParm values values from external sources:
   e.g. the transfer of the results from calibrator observations.





	     Cat II prediction
	     =================

Cat II sources include the fainter parametrised sources and extended
sources that exist as 4D images of CLEAN components. They are
predicted in patches: A (temporary) 4D image (I,Q,U,V) of a smallish
region of the sky is FFT'd into a gridded 4D uv-data cube
(XX,XY,YX,YY).  A node that predicts StokesQ values for a particular
correlation and domain/cells must interpolate the gridded values to
obtain vells along curved time-tracks in the frequency-planes.

It is easy enough to apply instrumental errors (incl ionospheric
phase) if the patch is so small that we may assume that they are
constant over it. Since this is not a very realistic assumption, we
are very pleased that the work of Sanjay, Tim and Kumar (STK, EVLA
Memo #84: "Solving for the antenna-based pointing errors") might be
generalised into a method for applying instrumental errors that vary
over the patch. It even allows us to solve for the M.E. parameters of
such effects (NB: Until now we assumed that Cat II sources were too
faint, but the combined flux in a patch will often be sufficent).

The trick is to include the instrumental effects in the interpolation
function that is needed to get from gridded uv-data to vells (f,t).
Although the details remain to be worked out, we may conjecture that:

   1) Any instrumental effect may be applied in this way (not only
   pointing errors).

   2) Derivatives w.r.t. M.E. parameters may be calculated as well.

   3) The interpolation function is simpler for smaller patches. In
   many cases we may get away with a linear inperpolation between the
   four nearest grid points. (STK do the interpolation for the entire
   field-of-view, which is computationally expensive because of the
   large convolution functions).

In short, our precious MeqTree paradigm might well be a suitable
vehicle for generalising the STK method to include arbitrary M.E.
parameters (not just pointing errors), and for minimising the amount
of processing by using patches (and by peeling the Cat I sources off
first).

Finally: We have been worried about the extra cost of predicting the
contamination from other sources while solving for M.E. parameters in
the direction of Cat I peeling sources. Perhaps the above method
should be used for this?




            Ionospheric phase
	    =================


- 2D phase screen across each individual voltage beam

- Large-scale phase structure above the array

How to reconcile them (sum of each other?).

Also important from S/N considerations.....




                  ========================================




















