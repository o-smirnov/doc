file: ../lofar/PSS/speed.doc

      ===========
      15 May 2005
      ===========

It has become clear that the node-overhead is a serious bottleneck.
There is little we can do about that before Calibration Day, but after
that we must find 'optimal' solutions, i.e. solutions that do not
affect those feature that we value most in the MeqTree system.

First the facts:

  -) With a single 12-hour domain, solving for (6) flux parameters is
  faster than NEWSTAR (~100 sec). This indicates that processing is
  fast enough, because we do more sophisticated thinsg than NEWSTAR.

  -) However, using a single mega-domain is only reasonable for
  flux-solutions, which change very little over 12 hours. In addition,
  it quickly exhausts the available memory. And finally, large domains
  go against the clever snipet-based things that MeqParms can do. 

  -) The processing overhead for each snippet in MAB's matrix343 tree
  is about 5 sec: It makes virtually no difference whether the snippet
  contains 6 or 64 frequency channels. Thus, snippets of 1 hour could
  be contemplated (60 s extra), but smaller ones become prohibitive.
  

What can we do about it (apart from parallelisation)?

  -) If memory allocation is a problem, this can be tackled by more
  'static' allocation schemes...

  -) If the hierarchy of function calls is a problem, this can be
  tackled by adopting a 'flatter' hierarchy. This probably has a price
  in terms of flexibility and maintainability.

  -) Reduce the number of nodes. The introduction of tensor nodes has
  already reduced this number very considerably. In addition, it is
  possible to combine the present atomic math nodes into specific
  nodes that represent (very) complex math expressions, and have many
  children. Obviously, such combination must be done mechanically, to
  avoid transcription errors that are very hard to trace. There are
  various ways:

     1) JEN already has a scheme where Glish nodes (which contain
     their expression as a Glish string) are automatically combined
     into larger nodes, that are translated into C++ .h/.cc files.
     After adaption for the new tensor nodes, this scheme should be
     pursued, and carried to the Python Tree Definition Language
     (planned for this summer).
  
     2) John Romein has been thinking about a scheme where an
     arbitrary C++ math expression (which may be very complex) is
     implemented in an optimised way. This could be used to optimise
     existing MeqTree nodes, or subtrees.

Ideally, we arrive at a hybrid solution, where the advantages of trees
(flexibility, locality, caching, visualisation, etc) are combined with
optimised code.



===========================================================================
From: Michiel Brentjens <brentjens@astron.nl>
To: "Oleg M. Smirnov" <smirnov@astron.nl>
Cc: Jan Noordam <noordam@astron.nl>, Maaijke Mevius <mevius@astron.nl>
Subject: Re: memory leaks and performance
Date: Wed, 18 May 2005 09:22:57 +0200

Hi Oleg,

The memory footprint is now about 150 MB after 370 timeslots, and it's 
__slowly_ increasing ( an MB or so every several tens of timeslots). With 
writing to the MS disabled, it takes on average 4.4 seconds to solve a 
timeslot. As soon as I'm in the office I'll try the BOIO thing.

For the time being I'm pretty happy :-)

Michiel

On Wednesday 18 May 2005 00:11, you wrote:
> Hi Michiel --
>
> I've found one ancient memory leak that seems to have been hiding until
> matrix math brought it to the surface. You need to update. Let me know
> how the footprint goes, there's still a minor leak somewhere in
> ParmTable, but it should be a lot less significant.
>
> Concerning performance, if you use the boio option for input and disable
> writing to an MS while you're experimenting (by omitting predict_column
> from outputrec), it goes down to about 4 seconds per 6 iterations.
> There's still some fat to be trimmed, but I don't expect any major
> breakthroughs until parallelization comes into play. Overhead-wise, such
> a small domain is just about the worst case imaginable.
>
> Cheers,
> Oleg

=============================================================================
From: "Oleg M. Smirnov" <smirnov@astron.nl>
To: Michiel Brentjens <brentjens@astron.nl>, 
 Jan Noordam <noordam@astron.nl>
Subject: some performance benchmarks
Date: Sun, 22 May 2005 15:42:44 +0200


Gents --

I've done some rough benchmarks with Michiel's current phase-solution 
tree. I have used 40 channels, and a tile size of 1, 50 and 100 
timeslots. The times per one domain (6 iterations) are as follows:

100 timeslots (4000 cells per domain): 30 s
50 timeslots (2000 cells):   17 s
1 timeslot (40 cells):       4.22 s

It's reasonable to assume that pure compute time is proportional to 
domain size, and overhead is constant. Doing the arithmetic, I get:

pure overhead per 6 iterations: 3.94 s
pure compute per 40 cells: 0.26 s, or 0.0065 s per cell

(Do note that this is a somewhat over-complicated tree for this 
particular problem -- extra Jones matrices, etc. -- so both numbers 
would decrease somewhat if we were to simplify it.)

The upshot is, at a domain size of ~600 cells, compute time becomes 
equal to overhead time. Beyond this point, the gains from any 
optimization for overhead diminish rapidly. The question is, what is the 
typical operational domain size we can expect in the future?

Cheers,
Oleg

===========================================================================



     

