file: ../MeqTrees/PSS4.08sep2003


      ***********************************************************
      Input document for the PSS4 monday-morning meeting (10:30).
      ***********************************************************
      Editor: JEN,  Last modified: thu 04 sep 11:30

---------------------------------------------------------------------
The monday-morning meeting is to report progress, and to DECIDE about
the items in this document. Therefore, the latter should be prepared
by making sure that they are thoroughly understood by the relevant
persons. Items can be submitted to me for inclusion. Preferably by
email, and thoughtfully formulated. I will distribute the last version
by email at least one hour before the meeting.  Decisions will be
enshrined in the MeqTree Handbook and other project documents.
---------------------------------------------------------------------

NB: Proposals should be expressed as much as possible in the usual
HandBook 'language' of Glish calls to the MeqNode interface object.

NB: I am toying with the idea of asking a short progress report (half
a page at most) from all group members by email on friday. For the
moment, we will just use the PSS4 target-list.




######################################################################
#######  Section 1: Things that are ready for a decision  ############
######################################################################

The following builds on the 'making waves' document by OMS/GVD. It has
been discussed intensively. I think that the conclusion is that the
document contained a number of ideas, which should be 


        Look-ahead capability
        =====================

The essence of the scheme proposed by OMS/GVD is a look-ahead
capability.  The most obvious beneficiary of this will be the spigot,
because finding the next domain of data may cost time.  More
generally, any node that is no longer needed for the current request
may start working on the next one.  

A look-ahead capability can be implemented by telling a tree
beforehand which sequence of requests it can expect:

- MeqNode.setRequest(MeqRequestSequence)

A MeqRequestSequence is a sequence of one or more MeqRequests, each of
which is characterised by a unique integer identifier (request_id).

When passing a MeqRequestSequence up the tree, each MeqExpr node keeps
only the vector of request_ids. But leaf-nodes like MeqParms and
MeqSpigots must of course hold the entire MeqRequestSequence. 

POTENTIAL PROBLEM: A node might receive different MeqRequestSequences
from different parents. Obviously, this is a problem that should be
avoided by the tree designer...

Since the MeqRequestSequence has to be stored by all MeqLeaves, it
should be as small as possible. Perhaps it helps if we may assume
that, very often, the successive requests will only differ in domain
(e.g. successive 10 sec strips). However, we should keep open the
possibility of a sequence of unrelated MeqRequest.

So, rather than a specifying a MeqRequest in the Old Scheme, the
.getResult() function now only needs to specify the request_id:

- MeqResult := MeqNode.getResult(request_id)

A node decides on the basis of the request_id whether its cache
already holds the requested result. If it does, it is returned
immediately. Otherwise, a MeqWait is returned, and the child will
remember which parent is waiting. The child will notify its parents
when it has changed, and the waiting parent issues the .getResult()
again. See also below.

Normally, the request_id will either be the current one, or the next
one in the list. However, one might conceive of situations where the
request_ids are issued in a different order, perhaps from different
parents. This is perhaps not efficient, but OK in principle, as long
as the MeqLeaves still have the specified requests available.  (OMS
wants it to be noted that he has reservations about the possibility of
going backwards, especially for a MeqSpigot. He might be right, but
that is no reason to design it out in this interface.)

The returned MeqResult can also be MeqWait, a MeqFail or a
MeqEndOfData (EOD). MeqResults are passed down the tree to the place
where the request was issued, where something sensible is done with
them...

A MeqRequestSequence can be OPEN_ENDED, i.e. it would continue to look
for subsequent domains of the same size, until told to stop, for
instance by:

- MeqNode.setRequest()        # i.e. an empty request sequence

An open-ended MeqRequestSequence allows an on-line mode.  With this in
mind, it seems a good idea to also have an EOD flag in a MeqResult.



        Keeping the trees optimally loaded
        ==================================

If nodes know which request they are likely to receive next, it will
often be efficient if they could start working on that as soon as they
are no longer needed for the current request. When asked for it, they
would then have the new result available in their cache more quickly.
The trick is for them to find out when their current result is no
longer needed.
 
One way is for the tree designer to specify, for a specific node, a
maximum number of cache reads, after which the node is free to do
other things.  This would only be used for certain nodes that are part
of a single tree, e.g. the 'uvcorr' node just before the 'flatten'
node in the OMS/GVD peeling tree. This node is expected to be read
only once.

Obviously, it would be better if it could be decided LOCALLY whether a
node can get on with the next request. The following function asks a
node whether it is 'mutable', i.e. whether it is possible for its
result to change without a change in Request:

- T/F := MeqNode.isMutable()

At this moment, this can only be True for nodes that have solvable
MeqParms in their sub-tree, because the MeqParms might be updated at
any time by a solver. In the future, there may be other cases. Perhaps
it can be True also if there are 'pushy' MeqSpigots in a subtree(?).

If a parent with a loaded cache knows that none of its children is
mutable, it knows that it will not need its children again FOR THE
CURRENT REQUEST/DOMAIN. So it might signal them that they are free to
start work on the next request. But a child can only do this if it has
received such a signal from all its parents.



	Cache control
        =============

The new scheme requires a new look at the cache control. On the one
hand, we do not have to decide anymore whether a result has to be
cached or not, because it will almost always spend some time in the
cache before it is read by a notified parent. On the other hand, even
if we now work with smallish domains, we still want to keep the volume
of simultaneously cached data to a minimum. Therefore, we must empty a
cache as soon as its result is no longer needed. In that case, we must
now also decide whether or not we want the node to start working on
the next request.  

There are three possibilities:

  1. The last result stays in the cache until the next request.

  2. The cache is emptied after a specified nr of reads (e.g. once),
  or when the current result has become invalid.

    


         Child-Parent notification
         =========================

The original principle was that parents know their children, but that
children do not know their parents. It appears that this is no longer
tenable, for at least three reasons:

   1. When a leaf-node like a MeqParm changes (e.g. when updated by a
   solver), it needs to notify ALL its parents that any results that
   they might have in their caches are no longer valid. 

   2. A child must notify a waiting parent that it now has the
   requested result. Of course a child can just notify ALL its
   parents, but we might as well use the available information.
   So, s child should not only remember that one (or more?) of its
   parents is waiting for a requested result, but it must also
   remember WHICH parent(s). 

   3. A child is free to start work on the next request if ALL its
   parents have indicated that they do not need it current result
   anymore.

TO BE DETERMINED: WE still have to devise rules for various situations
that might occur. For example, how does a node deal with clashing
requests from different parents? Especially when issued if a parent is
waiting for its request to be processed? Etc?

I understand from OMS that all this notifying can de done by making
the parents 'subscribe' to changes in specified fields of the
state-record of its children. 

This notification-by-subscription only uses DMI, and so it is simpler
than the full publish/subscribe mechanism, which requires Octopussy.
However, it might still be useful to ask a specific node to publish
its result (or whatever). This can be handled by the MeqServer, which
will subscribe to the specified field in the state-record of the
specified node:

- MeqNode.subscribe (nodename, fieldname)

This then replaces the MeqNode.publish() function in the Handbook. 


        ===================================
	Miscellaneous bits for the HandBook
	===================================

I have added a section on Explicit Assumptions. The first entry is
that we assume that freq cells in a domain all have the same width.

I will introduce a MeqLeaf concept, for those nodes that have no
children: MeqParm, MeqSpigot, MeqFreq, etc.. Note that MeqLeaf nodes
retain the full MeqRequestSequence, while MeqExpr nodes only need to
keep the corresponding vector of request_ids.

Variable MeqResults (see OMS/GVD): deferred. WE do not (yet) need this
extra complexity in this stage. May be good for 'integrate' node...?



#######################################################################
######	Section 2: Things to think about (to be discussed later)  #####
#######################################################################


        Node class/object naming convention
        ===================================

It is important that lists (trees) of nodenames are readable,
i.e. they that can be interpreted by humans and machines.

Classnames may have any characters, except dots (.). This is to
distinguish them from qualifier fields (see below).
All classnames have a prefix that indicates the kind of node:

- MeqExpr nodes:               mqe_
- MeqParm nodes:               mqp_
- MeqSpigot/MeqSink nodes:     mqs_
- MeqCondeq/MeqConstr nodes:   mqc_

The classnames get more specific from left to right:

- mqe_predict_XX_WSRT[_...]      # XX, XY, YX, YY all different
- mqe_predict_YY_WSRT[_...]
- mqe_ucoord                     # generic, fits into mqe_predict

- mqp_POS_X_station                # child for mqe_ucoord
- mqp_POS_EQ_RA               
- mqp_POL_STOKES_I               # mqp_stokesI0 (newstar)
- mqp_POL_STOKES_Q               # mqp_stokesQ% (newstar)
- mqp_rm                         # rotation measure (newstar)                       
- mqp_si                         # spectral index (newstar)
- mqp_phase_IONOS
- mqp_dphase_IONOS               # associated with mqp_ionophase

- mpc_condeq                     # mpc_condeq.c5.s23.s45.XX
- mpc_sumzero                    # MeqConstr 

- mps_MS                         # spigot 
- mpk_MS                         # sink

The complete nodename for an instantiation of the class has qualifiers
separated by dots:

- classname.qual1.qual2.qual3[...]

- mqe_predict_XX_WSRT.c5.s23.s45.XX  # XX qualifier for consistency 
- mqc_condeq.c5.s23.s45.XX       # cascaded peel (per peeling source)
- mqc_condeq.s23.s45.XX          # wsum peel (shared by peeling sources)
- mqs_spigot.s23.s45.XX          # 
- mqs_sink.s23.s45.XX            # 
- mqp_phase_IONOS.c5.s23.s45     # in the direction of source c5
- mqp_POS_EQ_RA.c5               # sky position of source c5               



        Variable peeling order per baseline/time
        ========================================

In peeling-selfcal, we solve for the instrumental parameters in the
direction of each peeling source as if it were the only source in the
sky. Contamination from other sources is either ignored, or roughly
taken into account. This only works if we peel in order of brightness.
However, the problem is that he same source may have a very different
visibility amplitude for different baselines, and even for different
times. Thus, we have to design the system in such a way that the
peeling ORDER can be different for different baselines, and can be
changed for the same baseline.
       
First of all, this means that 'pulling control' has to be taken away
from the solver, at least the ones that are associeted with peeling
sources. Rather, the MeqCondeq nodes should be aware of the current
peeling source, and send equations to the relevant solver. Taking this
one step further, the MeqCondeq might select the next peeling source
for its correlation by selecting the predicted visibility with the
largest amplitude at that particular time. 

I hesitate to say this, but the WSum approach does seem to be more
suitable for a variable peeling order than the rippling approach.
However, we should retain them both, because the latter would still be
attractive for preparing residual uv-data for imaging, since there the
peeling order can be identical and constant for all baselines. If the
rippling approach is indeed faster (at the cost of more nodes!), this
would even be necessary because we have to subtract all the Cat II
sources.

Of course the look-ahead capability discussed above remains a Good
Thing for either approach.


        Mission Statement?
        ==================

I am thinking about a kind of 'Mission Statement' for the MeqTree
system. It might state that the MeqTree kernel should be "minimal but
complete, and consistent". A second exhortation is about thinking
twice about names of concepts, classes, scripts and variables, since
"language controls our thinking". That kind of thing.


#########################################################################
#########################################################################
 
    

