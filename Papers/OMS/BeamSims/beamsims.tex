\documentclass{aa}

\usepackage{graphicx}
\usepackage{txfonts}
\usepackage{natbib}

\bibpunct{(}{)}{;}{a}{}{,} % to follow the A&A style

% shortcut to typeset a 2x2 matrix... there are a lot of these
\newcommand{\matrixtt}[4]{\left( \begin{array}{cc}#1&#2\\#3&#4\\\end{array} \right)}

% typographical conventions
% symbol used to indicate the Hermitian transpose
\newcommand{\herm}{H}
%% other common usage is: \newcommand{\herm}{\dagger}
% this typesets a Jones matrix
\newcommand{\jones}[2]{\vec {#1}_{#2}}
% this typesets an inverse Jones matrix
\newcommand{\jonesinv}[2]{\vec {#1}^{-1}_{#2}}
% this typesets a conjugate-transpose Jones matrix
\newcommand{\jonesT}[2]{\vec {#1}^{\herm}_{#2}}
% this typesets an inverse conjugate-transpose Jones matrix
\newcommand{\jonesTinv}[2]{\vec {#1}^{{\herm}-1}_{#2}}
% this typesets a coherency matrix
\newcommand{\coh}[2]{\mathsf{{#1}}_{{#2}}}

\newcommand{\EDIT}[1]{#1}


\begin{document}

\title{BeamSims: exploring the impact of primary beams\\on radio interferometric imaging and calibration.\\I. MeerKAT L-band continuum imaging and dynamic range}

\author{O.M. Smirnov\inst{\ref{inst:astron}} \and B.\ Frank\inst{\ref{inst:uct-astro}} \and I.\ Theron\inst{\ref{inst:emss}} \and I.\ Heywood\inst{\ref{inst:oap}} \and R.J.\ Baxter\inst{\ref{inst:uct-cs}}}

\institute{Netherlands Institute for Radio Astronomy (ASTRON),
  P.O. Box 2, 7990AA Dwingeloo, The Netherlands\\
  \email{smirnov@astron.nl}\label{inst:astron} \and
  UCT\label{inst:uct-astro} \and 
  EMSS\label{inst:emss} \and 
  Oxford Astrophysics\label{inst:oap} \and
  UCT\label{inst:uct-cs}  
}

\date{}

\titlerunning{BeamSims I. MeerKAT L-band continuum imaging and dynamic range}

\authorrunning{Smirnov et al.}

\abstract%
%optional context
{Primary beam patterns (or beamshapes for short) are emerging as a vital consideration both in the calibration of the new generation of radio interferometers, and in the design of future instruments such as the SKA. On the one hand this is due to a straightforward increase in sensitivity, which reveals instrumental effects that could be ignored on older and cruder instruments. On the other hand, some of the new designs introduce additional sources of beamshape instability. The resulting impact on telescope performance is far from obvious, especially since calibration techniques addressing these effects are still in their relative infancy. This issue needs to be studied urgently, both to improve the calibration of the new crop of SKA pathfinder instruments coming online now and in the near future, and to inform SKA design decisions.}
%aims
{This paper aims to introduce a simulations framework and methodology for quantifying the impact of beamshapes on radio interferometer performance and calibratability. We then apply the methodology to a comparative study of several possible MeerKAT dish designs.}
%methods
{Advances in software and computing power have made it possible both to derive detailed beamshapes from electromagnetic simulations, and to apply these in all-sky interferometric simulations. We use ...(Isak fill in)... to derive beamshapes, and then feed these into a MeqTrees-based simulations framework called BeamSims. Central to this is a new beam interpolation module, which can calculate beam gains based on gridded beamshapes specified via external files, while
applying effects such as sky rotation and pointing error. The simulated visibilities are then fed to a number of MeqTrees calibration scripts. The statistics of the resulting images are then used to derive telescope performance figures.}
%results
{Results: Isak sleeps well. Write the rest later.}
%optional conclusions
{Conclusions: write later.}

\keywords{Methods: numerical - Methods: analytical - Techniques: interferometric}

\maketitle

\section{Introduction}

The primary beam (PB) pattern, or beamshape, of a radio interferometer station\footnote{By which in general we mean a single correlated element, i.e. a single antenna such as a steerable dish, or a single compound beam of an aperture array or a phased array feed.} determines the underlying spatial response pattern: the interferometer per se samples the sky brightness distribution multiplied by the square of the primary beam. ``Good'' beamshapes effectively restrict the field of view (FoV) of the interferometer to the region of scientific interest, and minimize the response of the instrument to astrophysical or man-made (interfering) sources from outside the FoV. An ideal interferometer would have a perfectly stable beamshape that is identical across all stations and spatially limited (i.e. with null gain outside the FoV). Real-life beamshapes deviate from this ideal in a few important ways:

\begin{itemize}
\item They are not stable in time, in ways that are both predictable (e.g. parallactic rotation in a two-axis alt-az mount) and fundamentally unpredictable (environmental effects in the receiver electronics, mechanical deformations, pointing errors).
\item They differ from station to station, for similar reasons.
\item They are not quite spatially limited. The fundamental reason for this is that a beamshape is a Fourier transform of the aperture illumination function (AIF), and thus a spatially limited beamshape would require an infinite aperture. Finite-sized apertures result in non-zero primary beam \emph{sidelobes} that can be minimized, but never entirely eliminated, via careful antenna and optics design.
\end{itemize}

Beamshapes play a crucial role in the performance of radio interferometers. In particular, the sensitivity floor (i.e. the faintest detectable source) of a given radio interferometric map is subject to the following four limits:

{\bf 1. Thermal noise} is the simplest fundamental limit. In principle it can be made arbitrary low by increasing observation time, but only slowly, since it decreases as the square root of the latter.

{\bf 2. Classical confusion} is the the flux threshold below which the sky becomes too crowded for individual sources to be reliably resolved individually. It is determined by the spatial resolution of the interferometer, i.e. by its longest baselines.

{\bf 3. Calibration ``noise''} is a catch-all name for artefacts produced by the calibration process (even ones that are not particularly noise-like). These are usually caused by direction-dependent effects (DDEs), and specifically DDEs associated with beamshapes\footnote{At lower frequencies, ionospheric DDEs are increasingly dominant. We shall not consider them here.}.

{\bf 4. Sidelobe confusion}, or sidelobe ``noise'' is caused by the fact that both the PSF of a radio interferometer and the primary beams of its constituent stations never quite go to zero, even at large distances from 
the phase center and/or the pointing center. As a result, each pixel of the map in principle contains a noise-like contribution from {\bf all} sources in the sky.

The first two limits can be straightforwardly derived from a given telescope's design and engineering specifications. The other two limits are far less trivial to establish, and are particularly influenced by beamshapes. While the mechanisms of this influence are fairly well-understood from first principles, formal quantitative estimates of their effect on interferometric images are hard to derive analytically, and can often be counter-intuitive. This makes it rather difficult to translate traditional engineering figures of merit (FoMs), such as sidelobe level, pointing accuracy, polarization purity, etc. into interferometric FoMs that are relevant to the target science. Even conventional interferometric FoMs themselves can be misleading. In particular, imaging dynamic range (DR), often estimated as the ratio between the brightest source in the map and the faintest detectable feature, can be artificially inflated when a single very bright source is present, and says nothing about wide-field  performance, which is often limited by DDEs. To add to the uncertainty, algorithms for dealing with DDEs, such as AW-projection \citep{SB:imageplane} and differential gains \citep{RRIME3} are only starting to emerge, and their limitations are still poorly understood. The problem is rather urgent in the context of the SKA design process, where several competing dish designs need to have their interferometric performance characterized.

On the other hand, recent advances in software and computing power have made it possible to run brute force interferometric simulations on previously unprecedented scales. This makes it possible to construct a rather complete simulation of a given instrument and a target sky, play with different aspects of the design, and thus derive performance limits in an almost ``experimental'' manner. The present work presents one such simulation methodology. While the methodology is completely general, we will develop it for one specific use case, and will focus on the issues of sidelobe confusion and calibration noise in four possible MeerKAT dish configurations:

\begin{itemize}
  \item Offset Gregorian (OG) optics on a two-axis alt-az mount;
  \item OG on a three-axis or equatorial mount;
  \item Prime focus (PF) feed with four support struts, on a two-axis alt-az mount;
  \item PF on a three-axis or equatorial mount.
\end{itemize}

We shall also consider some variations on the optics (shaped dishes, different illumination patterns, randomized far sidelobes), and evaluate the same dishes in hypothetical interferometers that employ the station layouts of existing observatories (WSRT, EVLA, LOFAR), which provides some insight into how the effects under study scale with the number of stations.

The scope of this study is deliberately restricted to continuum imaging performance in the L-band. Our simulations pipeline uses full spectral information, together with the Jones formalism of the radio interferometer measurement equation (RIME), thus dealing with frequency and polarization as a matter of course. We therefore plan to conduct similar studies of polarimetric and spectroscopic performance, and document them in one or more follow-up papers.

\section{Simulations overview}

In broad terms, BeamSims is a ``brute force'' interferometer simulation. Our three primary inputs are a local sky model (LSM) corresponding to the science sky (this is essentially just a large source catalog), a set of primary beam patterns derived from EM simulations (see below), and an ``empty'' Measurement Set (MS) describing the observation (i.e. station layout, phase centre, timeslots, frequency channels, etc.) These are fed into a set of MeqTrees \citep{meqtrees} scripts that simulate ``corrupted'' visibilities using the mathematical framework of the radio interferometry measurement equation \citep[RIME; see][]{ME1,RRIME1}, and write them into the MS. 

The corrupted visibilities are then fed through a standard calibration pipeline (also MeqTrees-based), and imaged using the {\tt lwimager} tool (or CASA). The resulting images are then analysed and their statistics used to derive the results presented here.

% In very broad terms, our methodology comes down to generating a set of simulated science skies and instrumental error patterns. These are used to generate simulated ``corrupted'' visibilities using the mathematical framework of the radio interferometry measurement equation \citep[RIME; see][]{ME1,RRIME1}. The corrupted visibilities are then fed through a standard calibration pipeline, and the resulting images compared to the known science skies that we started with. From the comparison we derive the various FoMs.

\subsection{Model skies}

We use two sources for our model skies: the NRAO VLA Sky Survey \citep[NVSS:][]{NVSS} and the SKADS Simulated Skies extragalactic source database \citep[S$^3$-SEX:][]{S3-SEX}. 

The NVSS provides a 1.4 GHz source catalog covering the entire sky north of $-40\degr$ declination, complete from about 2.5 mJy up. We use the online SAO CATS interface \citep{SAO-CATS} to extract subsets of the NVSS. Our simulated instrument is meant to observe the Southern sky, for which no comparable survey exists. However, for the purposes of our study we only require a statistically realistic sky and not necessarily the true sky. We therefore adopt a strategy whereby extracts from the NVSS are shifted (via spherical coordinate transforms) south to provide model skies down to the 2.5 mJy level. As the nominal resolution of the NVSS is much lower than that of MeerKAT, there is little point in using the NVSS source extent information. We therefore treat all NVSS sources as point sources. 

For deeper models, we use samplings from the S$^3$-SEX simulation. This provides a statistically realistic distribution of extragalactic radio continuum sources in a $20\degr\times20\degr$ area, all the way down to nJy flux levels -- well below what is required for our purposes.

\subsection{Simulated PB patterns}

Isak, this is your section. Need to give an overview of the EM simulations, etc. Also need to explain what the three different OG variants are.

\subsection{Interferometric simulations}

The conventional approach to simulation in MeqTrees is to build a measurement equation using the RIME formalism, and evaluate this equation for every time and frequency bin of the desired MS. For an LSM consisting of a source catalog, a typical RIME used in the present study would look as follows:

  \begin{equation}\label{eq:rime0}
  \coh{V}{pq} = \jones{G}{p} \left ( \sum_{s} S_{spq} {\jones{E}{sp} K_{sp} \coh{B}{s} K^\herm_{sq} \jonesT{E}{sq}} \right ) \jonesT{G}{q}
  \end{equation}

Here, $\coh{B}{s}$ is the brightness matrix of source $s$, $K_{sp}$ is the (scalar) phase term associated with station $p$  and direction $s$, $\jones{E}{sp}$ is the E-Jones, or primary beam gain term for station $p$ and direction $s$, $S_{spq}$ is a scalar smearing factor accounting for time and bandwidth averaging \citep[implemented as per Eq. (23) of ][]{RRIME1}, $\jones{G}{p}$ is the direction-independent gain term associated with station $p$, and $\jonesT{A}{}$ is the Hermitian (or conjugate) transpose of $\jones{A}{}$.

\subsubsection{Implementing a tensor RIME}

Recent developments in MeqTrees have been driven by the tensor RIME formalism suggested by \citet{RRIME4}. In particular, the inner sum over $s$ in Eq.~(\ref{eq:rime0}) can rewritten as an Einstein sum:

\begin{equation}
\label{eq:trime}
\tens{X}^{pi}_{qj} = 
  \tens{S}_{q}^{ps}\tens{E}_{s\alpha}^{pi}\tens{K}_{s}^{p}
  \tens{B}^\alpha_{\beta s}
  \bar\tens{K}_{q}^{s}
  \bar\tens{E}_{qj}^{s\beta}
\end{equation}

Mathematically, this is a straightforward equivalent of the sum in Eq.~(\ref{eq:rime0}), expressed in terms of a {\em brightness tensor} $\tens{B}^\alpha_{\beta s}$ of rank $N_s\times2\times2$, and a \emph{Jones tensor} of rank $N_p\times N_s\times2\times2$, where $N_p$ is the number of stations, and $N_s$ is the number of sources.

This form of the RIME has guided implementation of a new {\em tensor mode} framework in MeqTrees, which has led to a drastic reduction in {\em housekeeping overhead}. In MeqTrees, the housekeeping overhead of any given tree is the resource cost (in terms of CPU and RAM) associated with constructing and processing the basic computational units called {\em nodes}\footnote{That is, over and above the cost of the computations per se.}. Older versions of MeqTrees used $2\times2$ matrices as the basic computational unit, with a separate subtree per each station pair $pq$. Given a matrix RIME such as Eq.~(\ref{eq:rime0}), the housekeeping overhead of this approach scales as $O(N_p^2 N_s)$. Consequently, script compilation time and RAM usage became the main bottleneck for large $N_p$ (e.g. $N_p\gtrsim 30$) given anything but a handful of $N_s$.

The current implementation of tensor mode goes half-way to Eq.~(\ref{eq:trime}), in that the basic computational unit becomes the brightness tensor $\tens{B}$, and a \emph{per-station} Jones tensor $\tens{E}_p$, both of rank $N_s\times2\times2$. This has required the addition of only a single node class to MeqTrees, called {\tt PSVTensor} (point source visibility tensor\footnote{Recent versions of PSVTensor are making the name somewhat inaccurate, since they also include support for extended Gaussian components. The class will probably be renamed to {\tt DSVTensor} in the near future, where D stands for ``discrete''.}), which implements Eq.~(\ref{eq:trime}) for a single $pq$ pair, given a brightness tensor, and any number of Jones tensors. Housekeeping costs then scale as the much more manageable $O(N_p^2+N_s)$. Note that the new tensor mode framework remains backwards-compatible with all the older MeqTrees Jones matrix modules, via the simple expedient of building up Jones tensors from $N_s$ separately generated Jones matrices. In this ``backwards compatibility'' regime the overhead scaling law is somewhat worse --  $O(N_p^2+N_p N_s)$ -- but this still better than the pure matrix regime. 

\subsubsection{Using GPUs for accelerated computation}

A second boon of using a tensor as the basic computational unit is that it groups computations together into larger chunks, rather than spreading them through different nodes of the tree. This approach proves far more amenable to a GPU implementation. One result of this was the development of a {\tt CUDAPSVTensor} node class, which is essentially a CUDA-accelerated version of {\tt PSVTensor}. Since the two node classes are identical in terms of interface, MeqTrees is able to select at script complication time whether to use one or the other.

NB: need to update this with some performance figures once Richard's CUDA nodes work.

\subsubsection{Practical performance limitations}

In practical terms, tensor mode has allowed us to run simulations of a full MeerKAT layout ($N_p=64$) 
with $N_s=10^3\sim10^4$ discrete model sources, with full $\tens{E}$-Jones treatment. To give some specific examples: the worst case scenario is a full per-station pointing error alt-az mount simulation (see below). This is completely dominated by evaluation of the $\tens{E}$-Jones tensor, which then assumes a different value for each source, station and time/frequency bin. Such a simulation (for $\sim5000$ sources, 480 timeslots, 8 frequency channels) takes on the order of 10 hours on a modern 8-core machine without a GPU. For simulations without pointing errors, only a single $\tens{E}$-Jones needs to be computed for all stations, and the same simulation runs to completion within an hour.

NB: need to update this with some more accurate performance figures once Richard's CUDA nodes work.

\subsubsection{Partitioning the model sky}

Assuming $10^3\sim10^4$ discrete sources as a reasonable upper limit on a ``fast'' simulation, how deep a sky (in terms of limiting flux) can we accurately simulate? This of course depends on FoV area. For example, given a limited $5\degr\times5\degr$ FoV, which at 1.4 GHz encompasses the main lobe and the first sidelobe of a MeerKAT primary beam, a full NVSS sampling (down to the limiting flux of 2.5 mJy) returns on the order of 1000 sources. On the other hand, for a full-sky FoV -- or more precisely a hemisphere (see simulations of Sect.~\ref{sec:fsn}) -- we get about 4000 sources at a cutoff flux of 0.5 Jy. 

Note that our performance bottleneck only applies to discrete models, for which we do the full $\tens{E}$-Jones treatment of Eq.~(\ref{eq:rime0}) or Eq.~(\ref{eq:trime}). If we dispense with $\tens{E}$-Jones (and all other direction-dependent Jones terms), then we can simulate a virtually unlimited number of fainter sources \emph{en masse}, by putting them into a sky image, applying an \emph{average} power beam to the image, and using an FFT to transform the image into predicted visibilities. There are at least three software tools that support\footnote{By which we mean capable, publicly available, and able to deal with Measurement Sets. The latter requirement rules out AIPS and other highly capable packages.}  this: the UVBrick component of MeqTrees \citep{Abdalla:uvbrick}, the CASA simulator tool, and the {\tt lwimager}\footnote{The ``lightweight imager'' utility a standalone tool developed by Ger van Diepen. It wraps the CASA imaging libraries into a standard command-line interface, and is thus especially convenient for use in pipelines and scripts. The tool is part of the {\tt casarest} binary package, and can be directly installed from the MeqTrees software repository.} tool. The latter has so far proven to be the most suitable, offering both a convenient single-command-line invocation (unlike CASA), and a full $w$-projection \citep{Cornwell:wproj} implementation (unlike the UVBrick, for which $w$-projection it is still in development). 

An image-based simulation derived in this way cannot be entirely accurate, since it omits the $\tens{E}$-Jones term (using at best a time- and station-average primary beam\footnote{The AW-projection algorithm \citep{SB:imageplane} does offer a way to incorporate virtually arbitrary DDEs into an FFT-based predict. Current implementations do not yet support arbitrary $\tens{E}$-Jones terms, and are therefore unsuitable for our purposes.}), and is also subject to pixellation errors. We therefore pick a flux threshold, and partition our sky models into two subsets:

\begin{itemize}
  \item A ``bright'' sky, which is simulated perfectly: that is, as discrete sources, using the full $\tens{E}$-Jones treatment of Eq.~(\ref{eq:rime0}) or Eq.~(\ref{eq:trime}).
  \item A ``faint'' sky, which is simulated approximately: that is, as a single image attenuated by the average power beam $|\vec E|^2$. Presumably, this is faint enough for such an approximation to be sufficient.
\end{itemize}

The two subsets can then be simulated separately, and the resulting visibilities simply added together.

For the simulations of Sect.~\ref{sec:dde} (limited FoV), it was quite convenient to place the bright--faint boundary between the NVSS and S$^3$ sources. That is, we used NVSS to provide a ``bright'' population of discrete sources from 3 mJy up, and S$^3$-SEX to provide a ``faint'' population from 3 mJy down. The latter was converted into a FITS image using the mapmaker script from the S$^3$-Tools package. 

For the full-sky simulations of Sect.~\ref{sec:fsn}, we dispensed with the faint sky altogether.

\subsubsection{Applying E-Jones}

In the mathematical framework of the RIME, primary beam gain is commonly designated by the $\vec{E}$-Jones matrix. 
The standard MeqTrees simulations framework includes a variety of Jones module implementations for incorporating different instrumental effects into the RIME. One of these ({\tt Cattery.Siamese.OMS.pybeams\_fits}) provides an implementation of 
E-Jones that reads complex beam patterns specified as FITS images (in $lm$ coordinates, i.e. in projected rectangular coordinates)


\subsection{Calibration}

Fundamental difficulty: calibration, etc.

\section{Sidelobe confusion}
\label{sec:fsn}

MeerKAT's classical confusion limit in L-band has been estimated at .1$\mu\mbox{Jy}$ (cite). This is the fundamental sensitivity limit set by the resolution of the telescope, i.e. the threshold below which faint sources get so crowded with respect to the PSF size that deconvolution is no longer possible. Thermal noise can be driven down to the confusion limit after about 100 days of integration, and two of the large survey projects (cite) expect to obtain such deep pointings. 

Reaching the classical confusion limit will require a substantial effort in calibration and deconvolution of the brighter sources. Here we consider whether

\subsection{Source counts and completeness estimates}
\label{sec:source-counts}


\section{DDEs and Calibration Errors}
\label{sec:dde}

Old text from draft version follows:

Non-identical and unstable beamshapes have long been known to cause subtle calibration artefacts, while distant sources coming in via PB sidelobes result in additional unwanted signal across the FoV. 

Traditional self-calibration and imaging techniques, which we'll refer to as {\em second-generation calibration} (2GC) following \citet{meqtrees}, implicitly assume that an interferometer observes some {\em apparent sky}, by which we refer to the intrinsic sky brightness distribution modulated by the antenna power beam as a function of direction. If the apparent sky is identical at every station, and time-invariable over the course of the observation, then an interferometer can be thought of as measuring the Fourier transform of that apparent sky (modulo a pair of per-station direction-independent complex gains, which are addressed by selfcal). Deviations from these assumption produce {\em direction-dependent effects} (DDEs), which cannot be dealt with using 2GC alone, and can thus limit imaging, spectroscopic and polarimetric performance \citep[see][for an overview]{RRIME2}. 

Traditional steerable dish arrays suffer from three types of beam-related DDEs:

\begin{itemize}
  \item In alt-az mounts, the sky rotates with respect to the dish (or, equivalently, the beam pattern rotates over the sky), producing time-variable gain variations towards off-axis sources. The more expensive equatorial (WSRT) or three-axis mounts (ASKAP) avoid this problem, but such solutions become prohibitively expensive for larger instruments. Sky rotation is a major limiting factor in wide-field VLA/EVLA imaging.

  \item \emph{Pointing errors} produce per-station, sometimes time-variable pointing offsets, which effectively shift the beam pattern on the sky. At WSRT, pointing errors are thought to be the dominant DDE at all except the lowest frequencies.

  \item Deformations of the dish geometry due to gravity, wind load and thermal effects, which translate into deformed beam patterns. This has been observed at the ATA \citep{Harp:ATA:deformations}. 
\end{itemize}

DDE error mechanisms may be well-understood, but formal quantitative estimates of their effect on the resulting images are difficult to derive and can often be counter-intuitive. This makes it rather difficult to translate traditional engineering figures of merit (FoMs), such as sidelobe level, pointing accuracy, polarization purity, into interferometric FoMs relevant to the target science. Even conventional interferometric FoMs themselves can be misleading. In particular, imaging dynamic range (DR), often estimated as the ratio between the brightest source in the map and the faintest detectable feature, can be artificially inflated when a single very bright source is present, and says nothing about wide-field  performance, which is often limited by DDEs. To add to the uncertainty, algorithms for dealing with DDEs, such as AW-projection \citep{SB:imageplane} and differential gains \citep{RRIME3} are only starting to emerge, and their limitations are still poorly understood. The problem is rather urgent in the context of the SKA design process, where several competing dish designs need to have their interferometric performance characterized.

Recent theoretical work by \citep{Wijnhnolds:imaging} and \citep{Carozzi:ixr} suggest better ``calibratability'' FoMs and more rigorous ways of deriving them. The object of the present work is to develop an alternative ``brute-force simulations'' methodology, which the available software tools are finally mature enough to support. The advantage of this approach is that even very subtle and complicated error mechanisms may be incorporated in the simulations in a reasonably straightforward manner, and translated into post-calibration ``science images'' that can then be directly evaluated against the scientific requirements. This has the not inconsiderable side benefit of providing future users of a telescope with simulated data to test their pipelines on.

In this work we focus on the MeerKAT design, which is a conventional single-pixel feed (SPF) steerable-dish interferometer, with rather unconventional (for an interferometer array) offset Gregorian (OG) optics on an alt-az mount. In terms of beam patterns, OGs trade off symmetry for smoother (and lower) sidelobes -- how this translates into scientific performance is not obvious, and is the subject of the present study. 

The other object of this paper is to establish and develop a rigorous methodology that can be applied to other instruments and other regimes. Examining every aspect of interferometric performance in sufficient depth is well beyond the scope of one paper. We have therefore decided to limit ourselves to the specific case of L-band continuum imaging. Extending this to other regimes (spectral line work, rotation measure synthesis), other frequencies and other instruments will be the subject of future papers, although we will  make a brief foray into the 14 GHz regime here.

% \section{Performance metrics}
% 
% This is a rather important part of the paper, since we don't really have a clear set of performance metrics at present. The obvious and best-understood one is dynamic range, but even there the problem is that we're also trying to estimate the performance of future algorithms! But besides this, there's spectral line issues and polarimetric fidelity.
% 
% \section{MeerKAT}
% 
% We will simulate all four possible combinations of prime focus vs. offset Gregorian feed, and rotating vs. stationary sky. 
% 
% For pointing errors: use a naive random sinusoid and/or Tony's ``physical'' pointing model. We can compare the results of the two and see if the elaborate model provides any significant difference.
% 
% For thermal/gravitational deformation: the KAT folks have some data (but also Athol?) Ludwig will investigate. We may get away with a simple warping of the interpolated l/m coordinate to simulate this effect.
% 
% \section{Other issues}
% 
% A-projection should be able to correct for some effects, but as long as an implementation is not available, we cannot really test this. However, the paper should make clear that our methodology is fully compatible: as soon as A-projection works, it can be plugged into the framework. In the meantime, we can probably work around this with some clever differential simulations: i.e. infer what the result of A-projection is going to be.
% 
% Different science cases will require different simulated skies, and different metrics. Tony/Ian/Brad can take the lead on this.
% 
% Some self-evaluation of the simulations framework is required. For exmaple, how accurate is the beam interpolation (especially in frequency?). Ludwig will get a few finely-sampled MeerKAT beams at one narrow frequency band, and we can compare the results with these against the results with a coarser-sampled beam.

\section{Conclusions}

\bibliographystyle{aa}

\bibliography{beamsims}


\end{document}
