file: ../PSS/MQT.02feb2005


      =============================================================
      Input for MeqTree (MQT) meeting, wednesday 02 feb 2005, 15:00
                                                   For once:  13:30 <---
      =============================================================

Participants:
  - RXA: Rob Assendorp
  - GVD: Ger van Diepen
  - MXM: Maaijke Mevius
  - RJN: Ronald Nijboer 
  - JEN: Jan Noordam
  - TAO: Tom Oosterloo
  - OMS: Oleg Smirnov
  - AGW: Tony Willis

For information:
  - MAB: Michiel Brentjens
  - WNB: Wim Brouw
  - AGB: Ger de Bruyn
  - MVH: Michiel van Haarlem
  - HAH: Hanno Holties
  - JXR: John Romein
  - KVS: Kjeld van der Schaaf
  - CMV: Marco de Vos



           Meeting schedule
	   ================

Wednesday 15:00, Multi-Media Room.

Please prepare by reading this thoroughly.



           ================
           Topics this week
	   ================

Since I neglected to submit a Quarterly Report to poor Marco, it seems
like a good moment to take stock of the current status of the MeqTree
project (note the name!). We will go through it togther.

A little morale booster: I think that I have stumbled upon the germ of
yet another breakthrough (after peeling) to improve the end result
while saving on processing cost. Because, as Ger loves to point out in
gruesome detail, it is still totally unclear whether we (or anybody)
will be able to handle the huge data volumes of LOFAR. In that sense,
we are a bit like James Bond: We are better equipped than most, but
ultimately we rely on inspiration along the way to save the day, and
thus the world. Fortunately, this never fails to materialise, so let
us move forward with vigour and confidence. 

A sobering thought: After Harvey's consultation meeting yesterday I
have come to the conclusion that we will have to 'flee forward': We
will have to work harder to demonstrate that our loose way of working
is more productive than the stalinist practices that could be the
result of some of the proposed reorganisations. I regard our project
as a shining example of 'interoperability', resulting in a product
with revolutionary features, which can be readily sold. But we must
prove that it actually delivers the goods.


	   ===================
           Short-term emphasis
	   ===================

Three points:

    -) Robustness of the Kernel: Exercise, exercise, exercise...!

    -) Canned forests (without LSM, for the moment: CPS-stage) 

    -) Water-hole:  

Things are going too slowly!!



           ===================
           Medium-term program
	   ===================

Everyone has his/her own area, with a lot of freedom, and minimum
dependence on others. Together, but individually self-propelled, we
move towards the following targets:

    Feb) Central Point Source (CPS): Visualisation, flagging,
    calibration (incl bandpass and polarisation), source subtraction,
    uv-data correction, inspection of residual images. Canned trees
    for all these activities, with automatic adaption to WSRT MS, and
    standard node classes only. Measurement of MeqTree speed (and
    bottlenecks?). MeqParm visualisation.

       During this month, the water-hole should emerge, teeming with
       vigorous life: Waterlogged forests, and the water-tool. Early
       MeqParm fiddling.

    Mar) Two dominating sources (3c343): Simple LSM, peeling chain.
    Estimation of 'other-source' contamination, and its effect on the
    selfcal solution.

    Apr) A more complicated field (...): Adaptation to LSM. Beamshape
    solution, including off-axis polarisation (17 MHz standing wave).

    May) A complex field (3c84): 1:10.000.000. Prediction of extended
    sources: LSM patches and uvbricks. 

    Jun) A LFFE field with a bright source (3c147): Facet
    imaging.

    Jul) A LFFE field without a bright source: Transfer of calibrator
    MeqParm values. Solve for ionospheric phase gradients (the start
    of a 'minimum' ionospheric model).  .




           =======================
	   Math node classes (RXA)
	   =======================

RXA has produced some new math classes, and is reviewing the set off
standard kernel math classes we have, and which are still missing. I
propose that we name him Math Master. He will produce (and maintain) a
document with an overview of these classes and their properties, and a
manual for writing such classes.

We have sharpened up the behaviour of MeqGaussNoise and MeqRandomNoise
for children that are vells/complex. OMS will show RXW the power of
vells-math for implementing math node classes. (NB: This is the
preferred way, since vellsmath takes flags into account, and various
dimenionality issues). 


           ================
           Water-hole (RXA)
           ================

RXA has produced a Python tool that allows a user to select a forest
and am MS (and in the future: a LSM), and start the system. The tool
will gradually become more sophisticated, driven by active use.

As a general principle, RXA will write the various services of the
water-tool in the form of meqbrowser plugins. Example: a request
editor. Then we can decide whether to make it available in the browser
also.
 

           =============
           MeqParm (MXM)
	   =============

Substantial work is needed on the MeqParm (node class and tables) on
short notice. The precise order is still to be discussed, but here are
a few issues:

   -) A simple, fast and optimal scheme to inter/extra polate stored
   funklets (or default values) to calculate values for an arbitrary
   request.

   -) Behaviour of a solvable MeqParm (the ADASS scheme).

   -) MeqParm visualisation.

   -) MeqParm editor (manual/semi-automatic).

   -) MeqParm cleanup tool (reduce fragmentation, edge discontinuities).

   -) MeqParm transfer (e.g. of calibrator values)

   -) MeqParm fiddler tool (getState/setState).

   -) Etc


    	   ================
           Solver (MAB/GVD)
	   ================

Michiel Brentjens will take over the MeqSolver node from GVD.
He will look at ways of using the solver metrics.


           ===================
           Facet imaging (WNB)
	   ===================

This is imaging in the narrow sense, i.e. just the transform of
'corrected' uv-data into residual image(s).  For the moment, we can
get by with the present AIPS++ imaging, but it is essential that
someone takes a hard look at the suitability in the medium term, and
eventually for LOFAR. WNB will get involved after in April, or
thereabouts.




	   ===================
           Visualisation: AGW:
	   ===================

I cannot emphasize enough that our system has an unprecedented number
of 'windows' on the processing. Every node can in principle be
inspected, either by itself or in groups. This MUST eventually lead to
new ways of doing things, by somebody....

AGW has sharpened up the 'realvsimag' visualisation, which now works
very nicely. But more (alpha) testing is needed, and we have to look
critically at labels, legends, titles etc. He has produced a draft
document with instructions for the use of MeqDataCollect nodes.

We need an idea for the default display of real numbers (realvsimag is
a waste of real estate.

We need to exercise the other plotting nodes in a similar way.

Our present plotting is perfect for interactive visualisation. We need
ideas for 'streaming' visualisation of the results of arbitrary nodes.
(See my note on the AIPS++ vieuwer of some weeks ago).




           ======================
	   Global Sky Model (TAO)
	   ======================

Nothing to report at this time.


           ==============================================
	   Local Sky Model (LSM) and related issues (RJN)
	   ==============================================

RJN has acquired some very useful experience in peeling 3c343/3c343.1
with aips++. The results are laid down in a document, which is highly
recommended.

He will now turn his attention back to the LSM, getting ready for the
stage beyond CPS-stage, where we process bright single point sources
in the centre of the field. He will first produce a document that
describes the various aspects of the LSM that we have discussed:

 -) Interfaces with:

    - GSM: For each observation, a relevant subset of sources must be
    obtained, and ordered in a suitable way. Afterwards, the GSM must
    be updated with the improved LSM.

    - Residual images: Improved LSM source parameters may be obtained
    from the residuals at the known source positions, and new sources
    may be identified for inclusion in the LSM. The relation between
    source parameters and image values is enshrined in MeqTrees.

    - Canned forests: The idea is that these are more or less generic,
    and can link up with a relevant LSM by node-names. This is
    possible because only 6 quantities are needed per source or patch:
    Stokes I,Q,U,V, and RA, DEC. The canned forest may consist of
    'peeling units' for each source/patch, which are linked into a
    peeling-chain automatically.


 -) We have come to the conclusion that there are only two kinds of
    sources: 

    - Point sources: Their contribution to the visbility function are
    predicted for each correlation separately, and image-plane effects
    can be simply applied. Their source parameters can be solved for
    in the uv-plane (selfcal).
 
    - Patches: Gridded 4D (RA, DEC, freq, IQUV) images of a small part
    of the sky. They may contain a mixture of sources from the
    component list and sources defined as CLEAN components. They are
    FFT'd to a gridded 4D visibility 'cube' (u, v, freq, corr), from
    which individual correlations (nodes) obtain their values by
    interpolation. Image-plane effects can be applied by modifying the
    inperpolation function. It is not practical to try and solve for
    patch source parameters by selfcal (this is better done from
    residual images), but it may be possible to solve for image-plane
    effects this way.
 
 -) RJN has taken on the three domain 'interpolation' jobs that are
 getting urgent: Re-sampling to/from domains with lower resolution
 (larger cells), and interpolation of 4D gridded visibility bricks.
 The latter includes the application of image-plane effects.

 -) In the short term, we need a LSM for 3c343/3c343.1.
 

           =======================
           On the use of uv-bricks
	   =======================

JEN has started a document "on the use of uv-bricks in MeqTree
processing". They might turn out to be useful for more than just patch
prediction (see above). Other possibilities are:

  -) Reduction/elimination of 'other-source' contamination in peeling.

  -) LSM subtraction without knowing the position and flux of every
  source individually. After all, we are not interested in those, just
  in their removal. 

  -) Selfcal without LSM: a form of weak redundancy, smoothing the
  rubber sheet. Especially around the phase centre.


           ===================== 
           Tree generation (JEN)
	   =====================


...



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


           ====================
	   Layered solver (GVD)
	   ====================


Ger van Diepen and I had a discussion about solvers and
super-solvers. He will summarize this in a separate email.

Here the background and ideas about a 'layered' solver.

The LOFAR visibility data will be distributed over several machines.
The distribution will most likely be done along the beam, spectral
window and baseline axes.
When solving for .e.g. the station ionosphere parameters, one needs in
principle all data to do the parameter fit.
So there need to be a central solver receiving equations from the
machines holding the data. For LOFAR this means that the solver receives
4950*4*1*5*201 complex data values which is about 320 MBytes to do a
single fit. This is quite a lot
    4950 baselines
    4 correlations
   1 time cell
   5 frequency cells
  200 derivatives (200 solvable station parameters)

However, it might well be possible that the first iterations in finding
the final solution can be done locally using only a subset of the data.
For example, when distributing the data long the baseline axis, each
local node can solve for the stations for which it has sufficient data.
Those solvable stations can be chosen such that all of them are solved,
but on not more than one machine.
In this way only a subset of the data is used and nothing has to be
sent to a central solver. It saves a lot of processing and
communication. Only the final iterations might need to be done by a
central solver.

When using a central solver, it might be possible that the matrix used
internally by the solver is filled in a distributed way. So instead of
sending the equations to the central solver, the local solver fills its
matrix and sends it to the central solver. Potentially it means sending
far fewer data.

It means that in the PSS system 2 types of solvers are needed.
- a local solver which can do a real solve or only fill the matrix.
   A request rider triggers if a real solve will be done.
- a central solver combining the local matrices and doing the final
solve.

To be able to do it using Wim's AIPS++ solver, we have to ask Wim if
this can be made possible in his LSQFit class.




                    =====================================
                    =====================================






















